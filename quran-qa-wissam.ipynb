{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":19424,"status":"ok","timestamp":1649137297203,"user":{"displayName":"Qa Task","userId":"02359377570863894136"},"user_tz":-180},"id":"sJcT_u8NVaA0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"debb3c86-66ac-4704-f5ec-9a5329f51b24"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1649137297203,"user":{"displayName":"Qa Task","userId":"02359377570863894136"},"user_tz":-180},"id":"iQItrfLQYCx2","outputId":"37a7c36f-78e5-47ce-9683-669329baec92"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr  5 05:41:37 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24933,"status":"ok","timestamp":1649137322132,"user":{"displayName":"Qa Task","userId":"02359377570863894136"},"user_tz":-180},"id":"ZkoOGYWeXjhl","outputId":"26dc8b60-75d2-4fd2-f032-fe1337937753"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'quranqa'...\n","remote: Enumerating objects: 261, done.\u001b[K\n","remote: Counting objects: 100% (98/98), done.\u001b[K\n","remote: Compressing objects: 100% (76/76), done.\u001b[K\n","remote: Total 261 (delta 35), reused 70 (delta 22), pack-reused 163\u001b[K\n","Receiving objects: 100% (261/261), 300.16 KiB | 12.51 MiB/s, done.\n","Resolving deltas: 100% (89/89), done.\n","Collecting git+https://github.com/neuml/txtai\n","  Cloning https://github.com/neuml/txtai to /tmp/pip-req-build-5fi9v9bj\n","  Running command git clone -q https://github.com/neuml/txtai /tmp/pip-req-build-5fi9v9bj\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 15.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Collecting pyyaml>=5.3\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 77.9 MB/s \n","\u001b[?25hCollecting tokenizers>=0.10.3\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 84.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (1.21.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (1.10.0+cu111)\n","Collecting transformers>=4.12.3\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 54.1 MB/s \n","\u001b[?25hCollecting faiss-cpu>=1.7.1.post2\n","  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 91.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->txtai==4.4.0) (3.10.0.2)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 84.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (4.63.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (2019.12.20)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.12.3->txtai==4.4.0) (3.0.7)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 92.3 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 83.7 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 89.9 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (2.10)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 93.6 MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 89.3 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.6 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 98.1 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.12.3->txtai==4.4.0) (3.7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.12.3->txtai==4.4.0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.12.3->txtai==4.4.0) (7.1.2)\n","Building wheels for collected packages: txtai\n","  Building wheel for txtai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for txtai: filename=txtai-4.4.0-py3-none-any.whl size=131962 sha256=97aa7eb846bea0e4ddd0a1d0faaf17c6d0210639d0ddf916171823fc6d6993dd\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-l732c0hc/wheels/83/d6/ae/6b41733966092887bf61f691622261d990943588a03e5cd0be\n","Successfully built txtai\n","Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, huggingface-hub, fsspec, aiohttp, xxhash, transformers, responses, faiss-cpu, txtai, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 faiss-cpu-1.7.2 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.4.0 multidict-6.0.2 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0 txtai-4.4.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n","Collecting farasapy\n","  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.63.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n","Installing collected packages: farasapy\n","Successfully installed farasapy-0.0.14\n"]}],"source":["!git clone https://gitlab.com/bigirqu/quranqa.git\n","!pip install git+https://github.com/neuml/txtai datasets pandas\n","!pip install farasapy"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cNT1MBHKXjhs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649137335881,"user_tz":-180,"elapsed":13766,"user":{"displayName":"Qa Task","userId":"02359377570863894136"}},"outputId":"907a9682-49f7-4208-8ead-c347232aaddf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jsonlines\n","  Downloading jsonlines-3.0.0-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonlines) (3.10.0.2)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from jsonlines) (21.4.0)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-3.0.0\n"]}],"source":["!pip install jsonlines\n","import jsonlines\n","\n","\n","import sys\n","sys.path.insert(1, '/content/quranqa/code')\n","import quranqa22_eval\n","from collections import defaultdict\n","from farasa.diacratizer import FarasaDiacritizer \n","from farasa.ner import FarasaNamedEntityRecognizer \n","from farasa.pos import FarasaPOSTagger \n","from farasa.segmenter import FarasaSegmenter \n","from farasa.stemmer import FarasaStemmer\n","from gensim import corpora, models, similarities\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","from transformers import EarlyStoppingCallback\n","from txtai.embeddings import Embeddings\n","from txtai.pipeline import Extractor\n","from txtai.pipeline import HFTrainer\n","from txtai.pipeline import Questions\n","from txtai.pipeline import Similarity\n","import operator\n","import pandas as pd\n","import pprint\n","import read_write_qrcd as q_reader\n","import torch, string, re, os, json"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649137335882,"user":{"displayName":"Qa Task","userId":"02359377570863894136"},"user_tz":-180},"id":"I12lpmBwXjht","outputId":"5404534e-0bf7-4cfd-bd3e-c07aaeb13167"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 710 records from ./quranqa/datasets/qrcd_v1.1_train.jsonl\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","Loaded 274 records from ./quranqa/datasets/qrcd_v1.1_test_noAnswers.jsonl\n"]}],"source":["train_context_question_objects = q_reader.load_jsonl('./quranqa/datasets/qrcd_v1.1_train.jsonl')\n","dev_context_question_objects = q_reader.load_jsonl('./quranqa/datasets/qrcd_v1.1_dev.jsonl')\n","test_context_question_objects = q_reader.load_jsonl('./quranqa/datasets/qrcd_v1.1_test_noAnswers.jsonl')\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jddATQh7Xjhu","executionInfo":{"status":"ok","timestamp":1649137337523,"user_tz":-180,"elapsed":1646,"user":{"displayName":"Qa Task","userId":"02359377570863894136"}},"colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"5542b07b-0726-4e32-92a0-43d170ceeb92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"with jsonlines.open('/content/drive/MyDrive/test_data2.jsonl', mode='w') as writer:\\n  for w in test_data2:\\n    writer.write(w)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["\n","train_data = [dict({\"pq_id\": context_question_object['pq_id'],\n","                    #\"question\": quranqa22_eval.normalize_text(context_question_object.question),\n","                    \"question\": context_question_object['question'],\n","                    \"context\": context_question_object['passage'], \n","                    \"answers\": r['text']})\n","              for context_question_object in train_context_question_objects\n","              for r in context_question_object['answers']]\n","\n","dev_data = [dict({\"pq_id\": context_question_object['pq_id'],\n","                  #\"question\": quranqa22_eval.normalize_text(context_question_object.question),\n","                  \"question\": context_question_object['question'],\n","                  \"context\": context_question_object['passage'],\n","                  \"answers\": r['text']})\n","            for context_question_object in dev_context_question_objects\n","            for r in context_question_object['answers']]\n","\n","test_data = [dict({\"pq_id\": context_question_object['pq_id'],\n","                  #\"question\": quranqa22_eval.normalize_text(context_question_object.question),\n","                  \"question\": context_question_object['question'],\n","                  \"context\": context_question_object['passage'],\n","                   })\n","            for context_question_object in test_context_question_objects]\n","\n","dev_train_data = train_data + dev_data\n","\n","train_data2 = pd.read_csv('/content/drive/MyDrive/train_dataset.csv',delimiter='\\t')\n","train_data2 = train_data2.to_dict('records')\n","\n","dev_train_data2 = pd.read_csv('/content/drive/MyDrive/dev_train_dataset.csv',delimiter='\\t')\n","dev_train_data2 = dev_train_data2.to_dict('records')\n","\n","test_data2 = pd.read_csv('/content/drive/MyDrive/test_dataset.csv',delimiter='\\t')\n","test_data2 = test_data2.to_dict('records')\n","\n","'''with jsonlines.open('/content/drive/MyDrive/test_data2.jsonl', mode='w') as writer:\n","  for w in test_data2:\n","    writer.write(w)'''"]},{"cell_type":"code","source":["test_data3 = []\n","with jsonlines.open('/content/drive/MyDrive/test_data2.jsonl', mode='w') as writer:\n","  for i,w in enumerate(test_data2):\n","    d0 = {'start_char': w['context'].find(w['answers'].strip()), 'text': w['answers'].strip()}\n","    d1={'pq_id':w['pq_id'],'question':w['question'],'passage':w['context'],'answers':[d0]}\n","    d2={'pq_id':w['pq_id'],'question':w['question'],'context':w['context'],'answers':[d0]}\n","    writer.write(d1)\n","    test_data3.append(d2)\n"],"metadata":{"id":"WdwLLWnNfyI5","executionInfo":{"status":"ok","timestamp":1649137337856,"user_tz":-180,"elapsed":338,"user":{"displayName":"Qa Task","userId":"02359377570863894136"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["for x in test_data2:\n","  if x['answers'] not in x['context']:\n","    print(x)"],"metadata":{"id":"_Is2tM5IGag5","executionInfo":{"status":"ok","timestamp":1649137337856,"user_tz":-180,"elapsed":4,"user":{"displayName":"Qa Task","userId":"02359377570863894136"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUbGcz9k5qwa"},"outputs":[],"source":["dev_data_df = pd.DataFrame(dev_data)\n","dev_data_df.to_csv('dev.csv', sep='\\t')\n","train_data_df = pd.DataFrame(train_data)\n","train_data_df.to_csv('train.csv', sep='\\t')\n","test_data_df = pd.DataFrame(test_data)\n","test_data_df.to_csv('test.csv', sep='\\t')\n","\n","!cp *.csv /content/drive/MyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yKCvBkzHXjhv"},"outputs":[],"source":["pretrained_models = [#\"wissamantoun/araelectra-base-artydiqa\", #num_train_epochs=2\n","                     #\"salti/AraElectra-base-finetuned-ARCD\", #num_train_epochs=8\n","                     \"gfdgdfgdg/arap_qa_bert_large_v2\",\n","                     #\"gfdgdfgdg/arap_qa_bert_v2\",\n","                     #\"gfdgdfgdg/arap_qa_bert\"\n","                     ]\n","\n","\n","def tokenize_function(row,tokenizer):\n","    return tokenizer.encode_plus(row['question'], row['context'], \n","                                 return_tensors='pt', padding=True, \n","                                 truncation=True,max_length=512, \n","                                 add_special_tokens = True)\n","\n","topk_n = 20\n","def get_prediction(row, model, tokenizer,top_rank):\n","    inputs = tokenize_function(row,tokenizer)\n","    output = model(**inputs)\n","    \n","    #print(torch.topk(output.start_logits.flatten(), topk_n))\n","    answer_starts_val = torch.topk(output.start_logits.flatten(), topk_n).values\n","    answer_ends_val = torch.topk(output.end_logits.flatten(), topk_n).values\n","    answer_starts = torch.topk(output.start_logits.flatten(), topk_n).indices\n","    answer_ends = torch.topk(output.end_logits.flatten(), topk_n).indices\n","    \n","    answers = []\n","    rank = 1\n","    for answer_start,answer_end,answer_start_v,answer_end_v in zip(answer_starts,answer_ends,answer_starts_val,answer_ends_val):\n","        answer = {}\n","        ans = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end+1]))\n","        if len(ans.strip())>0:\n","            answer[\"answer\"] = ans\n","            answer[\"rank\"] = rank\n","            answer[\"score\"] = answer_start_v.item()+answer_end_v.item()\n","            rank = rank +1\n","            answers.append(answer)\n","        if rank > top_rank:\n","            break\n","        #answer = str(answer_start_v.item())+' '+ answer +' '+ str(answer_end_v.item())\n","    return answers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y78egEpg1vSI"},"outputs":[],"source":["def normalize_text(s):\n","    \"\"\"remove punctuation, some stopwords and extra whitespace.\"\"\"\n","    def remove_stopWords(text):\n","        terms = []\n","        stopWords = {'من', 'الى', 'إلى', 'عن', 'على', 'في', 'حتى'}\n","        for term in text.split():\n","            if term not in stopWords:\n","                terms.append(term)\n","        return \" \".join(terms)\n","\n","    def white_space_fix(text):\n","        return ' '.join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        # Arabic punctuation\n","        exclude.add('،')\n","        exclude.add('؛')\n","        exclude.add('؟')\n","        print(text)\n","        return ''.join(ch for ch in text if ch not in exclude)\n","\n","    return white_space_fix(remove_stopWords((s)))\n","\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = prediction.split()\n","    truth_tokens = truth.split()\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    \n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","    \n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","    \n","    return 2 * (prec * rec) / (prec + rec)\n","\n","def compute_metrics(pred, labels):\n","    pred = np.argmax(pred, axis=1)\n","\n","    exact_match = compute_exact_match(pred, labels)\n","    f1 = compute_f1(pred, labels)\n","\n","    return { \"f1\": f1, \"exact_match\": exact_match}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8dprFZjXjhw"},"outputs":[],"source":["\n","def Fine_tune(model_name,traindata,devdata,num_train_epochs,batch_size):\n","    trainer = HFTrainer()\n","\n","    return trainer(model_name, traindata,#devdata,\n","                   task=\"question-answering\",\n","                   metric_for_best_model = 'f1',\n","                   #evaluation_strategy ='epoch',\n","                   #eval_steps = 500, # Evaluation and Save happens every 50 steps\n","                   #save_total_limit = 15,\n","                   save_strategy='no',\n","                   learning_rate=2e-5,\n","                   per_device_train_batch_size=batch_size,\n","                   #per_device_eval_batch_size=batch_size,\n","                   num_train_epochs=num_train_epochs,\n","                   weight_decay=0.01,\n","                   #load_best_model_at_end=False, # change this to True after hyperparameter tuning\n","                   )\n","    #return trainer(model_name, data, task=\"question-answering\", num_train_epochs=num_train_epochs)#num_train_epochs=10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DobWLdpkjnh5"},"outputs":[],"source":["def ir(data_item={}, query_key='question', docs_key='context', index_method='lsi', dims=4) -> list:\n","    # get data items \n","    docs = [ver.strip() for ver in data_item.get(docs_key).split('.') if ver.strip()]\n","    query = data_item.get(query_key)\n","    stoplist = ''.split()\n","    texts = [\n","        [word for word in doc.split() if word not in stoplist]\n","        for doc in docs\n","    ]\n","\n","    # build dictionary and corpus \n","    dictionary = corpora.Dictionary(texts)\n","    corpus = [dictionary.doc2bow(text) for text in texts]\n","\n","    # build tfidf & lsi models \n","    tfidf = models.TfidfModel(corpus) \n","    corpus_tfidf = tfidf[corpus]\n","    lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=dims)\n","    corpus_lsi = lsi_model[corpus_tfidf]\n","\n","    # generate query BOW vector and LSI vector from the question \n","    query_bow = query.replace('؟', '').replace('\"', '').split()\n","    vec_bow = dictionary.doc2bow(query_bow)\n","    vec_lsi = lsi_model[vec_bow]\n","\n","    result = []\n","    try:\n","        # generate tfidf and lsi indices \n","        lsi_index = similarities.MatrixSimilarity(corpus_lsi)\n","        tfidf_index = similarities.MatrixSimilarity(corpus_tfidf)\n","        \n","        \n","        # get similarities between queries and docs \n","        tfidf_sims = tfidf_index[vec_bow]\n","        lsi_sims = lsi_index[vec_lsi]\n","\n","        # sort documents according to similarties \n","        \n","        if index_method == 'tfidf':\n","            sims = tfidf_sims\n","        else:\n","            sims = lsi_sims\n","        \n","        sims = sorted(enumerate(sims), key=lambda item: -item[1])\n","        for doc_position, doc_score in sims:\n","            result.append( (doc_score, docs[doc_position]) )\n","    except:\n","        for doc in docs:\n","            result.append( (0.0, doc) )\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVQO4QEoohvM"},"outputs":[],"source":["def filter_context(in_data):\n","  in_data = [dict(in_t) for in_t in in_data]\n","\n","  out_data = []\n","  for data in in_data:\n","    filtered = ir(data_item=data)\n","    j=0\n","    for i in reversed(filtered): \n","      j=j+1\n","      sc,worest = i\n","      context = data['context']\n","      if sc != 0:\n","        context = context.replace(worest,'')\n","      if j== 1:\n","        break\n","    context = context.replace('  ',' ')\n","    context = context.replace(' .','.')\n","    context = context.replace('..','.')\n","    data['context'] = context\n","    out_data.append(data)\n","  return out_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1991,"status":"ok","timestamp":1648635243201,"user":{"displayName":"Qa Task","userId":"02359377570863894136"},"user_tz":-180},"id":"7mxDPxrckujk","outputId":"75b02068-512a-45d6-99c3-aa8af140c0f6"},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-03-30 10:14:00,739 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,743 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,751 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,755 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,763 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,767 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,778 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,782 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,789 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,793 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,803 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,806 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,828 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,834 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,853 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,864 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,888 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,897 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,921 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,930 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,949 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,959 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,970 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,976 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,985 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:00,989 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,003 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,009 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,022 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,027 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,043 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,046 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,057 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,061 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,070 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,074 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,084 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,090 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,109 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,118 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,130 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,135 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,143 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,148 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,158 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,164 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,174 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,178 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,189 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,195 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,208 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,215 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,228 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,234 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,248 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,254 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,266 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,272 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,282 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,286 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,297 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,302 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,315 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,321 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,331 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,337 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,349 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,355 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,367 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,372 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,383 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,388 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,398 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,403 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,413 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,419 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,428 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,432 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,445 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,452 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,463 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,467 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,478 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,484 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,498 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,504 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,515 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,519 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,534 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,541 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,556 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,565 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,578 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,583 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,592 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,597 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,605 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,612 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,621 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,627 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,639 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,644 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,656 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,662 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,674 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,681 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,693 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,699 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,712 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,718 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,748 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,755 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,766 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,771 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,779 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,783 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,799 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,806 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,817 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,822 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,834 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,845 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,861 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,869 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,880 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,887 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,896 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,902 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,910 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,916 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,925 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,931 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","/usr/local/lib/python3.7/dist-packages/gensim/models/lsimodel.py:100: RuntimeWarning: invalid value encountered in true_divide\n","  rel_spectrum = np.abs(1.0 - np.cumsum(s / np.sum(s)))\n","2022-03-30 10:14:01,939 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,951 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,958 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,973 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,979 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,988 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:01,993 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,001 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,007 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,016 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,021 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,032 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,038 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,048 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,053 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,064 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,070 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,083 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,090 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,103 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,109 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,123 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,129 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,140 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,145 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,158 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,165 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,178 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,184 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,194 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,199 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,207 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,212 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,221 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,226 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,235 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,240 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,251 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,257 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,267 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,272 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,282 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,285 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,292 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,294 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,301 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,304 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,311 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,313 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,321 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,324 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,338 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,344 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,356 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,362 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,372 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,377 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,387 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,392 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,401 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,406 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,415 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,420 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,430 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,434 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,445 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,451 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,463 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,472 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,481 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,483 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,495 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,509 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,527 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,536 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,552 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,561 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,578 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,588 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,600 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,607 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,620 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,627 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,640 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,646 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,661 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,669 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,685 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,694 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,707 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,713 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,726 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,733 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,746 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,752 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,762 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,768 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,778 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,784 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,794 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,800 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,807 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,810 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,817 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,820 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,827 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,830 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,845 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,851 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,862 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,867 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,878 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,884 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,894 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,899 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,907 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,911 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,922 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,927 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,939 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,945 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,957 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n","2022-03-30 10:14:02,963 [WARNING] __init__: scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"]}],"source":["\n","f_dev_data = filter_context(dev_data)\n","if f_dev_data == dev_data:\n","    print('0000000000000')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YTn4NqeXjhx"},"outputs":[],"source":["\n","def test_model2(tokenizer,model,data):\n","  questions = Questions(path=(model, tokenizer), gpu=True)\n","  result ={}\n","  for row in data:\n","    da = row['context'].split('.')\n","    qu = [row['question']]\n","    ans = list(set(questions([qu[0]] * len(da), da)))\n","    result[row[\"pq_id\"]] = ans\n","  return result\n","\n","def test_model(tokenizer,model,data,top_rank):\n","  result = {}\n","  for row in data:\n","    pred = get_prediction(row, model, tokenizer,top_rank)\n","    result[row[\"pq_id\"]] = pred\n","  return result"]},{"cell_type":"code","source":["!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/QQATeam_Run01.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/QQATeam_Run02.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/QQATeam_Run03.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/QQATeam_Run04.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/QQATeam_Run05.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/QQATeam_Run06.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OesltJM7UP1-","executionInfo":{"status":"ok","timestamp":1648635411732,"user_tz":-180,"elapsed":54278,"user":{"displayName":"Qa Task","userId":"02359377570863894136"}},"outputId":"98618e63-c9ee-48bf-9429-68d98c2da5eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2022-03-30 10:15:57,496 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 274 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5255006666996809, \"exact_match\": 0.2116788321167883, \"f1\": 0.46615448675765475}\n","[2022-03-30 10:16:06,687 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 274 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5625351340918143, \"exact_match\": 0.24452554744525548, \"f1\": 0.5184042367570512}\n","[2022-03-30 10:16:15,746 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 274 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5416605570150471, \"exact_match\": 0.2116788321167883, \"f1\": 0.5100157052331109}\n","[2022-03-30 10:16:25,330 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 274 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5255006666996809, \"exact_match\": 0.2116788321167883, \"f1\": 0.46615448675765475}\n","[2022-03-30 10:16:33,531 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 274 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5625351340918143, \"exact_match\": 0.24452554744525548, \"f1\": 0.5184042367570512}\n","[2022-03-30 10:16:42,016 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 274 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5409113626863279, \"exact_match\": 0.20072992700729927, \"f1\": 0.509114211508569}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11654069,"status":"error","timestamp":1648635136384,"user":{"displayName":"Qa Task","userId":"02359377570863894136"},"user_tz":-180},"id":"CJYAT9WeXjhy","outputId":"fff4f45d-e75f-4204-b3e7-bb7b163eca8b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","###################wissamantoun/araelectra-base-artydiqa\n","[2022-03-30 06:58:08,614 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.14, \"exact_match\": 0.0, \"f1\": 0.14}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1978' max='1978' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1978/1978 03:20, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.483400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.162100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.280700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2 2 2\n","[2022-03-30 07:01:42,990 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.17391304347826086, \"exact_match\": 0.0, \"f1\": 0.17391304347826086}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2967' max='2967' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2967/2967 05:00, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.491000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.155900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.360900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.370500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.906000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["3 3 3\n","[2022-03-30 07:06:57,475 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.17391304347826086, \"exact_match\": 0.0, \"f1\": 0.17391304347826086}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3956' max='3956' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3956/3956 06:41, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.495300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.160400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.394900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.419500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.963600</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.115200</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.760200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["4 4 4\n","[2022-03-30 07:13:52,274 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.25, \"exact_match\": 0.0, \"f1\": 0.25}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4945' max='4945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4945/4945 08:22, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.497100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.167700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.419100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.458800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.008400</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.170100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.809600</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.761500</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.568900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["5 5 5\n","[2022-03-30 07:22:28,108 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.25, \"exact_match\": 0.0, \"f1\": 0.25}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='5934' max='5934' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5934/5934 10:03, Epoch 6/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.498300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.168200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.424300</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.456500</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.087000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.229800</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.847800</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.824000</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.643300</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.437900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["6 6 6\n","[2022-03-30 07:32:44,591 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.25, \"exact_match\": 0.0, \"f1\": 0.25}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='6923' max='6923' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [6923/6923 11:44, Epoch 7/7]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.499100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.169000</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.431100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.458300</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.039000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.230600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.856500</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.946700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.653300</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.715600</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.484300</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.666300</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.425100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["7 7 7\n","[2022-03-30 07:44:42,363 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.2978723404255319, \"exact_match\": 0.0, \"f1\": 0.2978723404255319}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='7912' max='7912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [7912/7912 13:25, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.499800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.171300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.439000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.492900</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.056000</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.269100</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.890900</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.902200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.702600</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.743000</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.485200</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.715800</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.434800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.552400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.422300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["8 8 8\n","[2022-03-30 07:58:20,945 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.2978723404255319, \"exact_match\": 0.0, \"f1\": 0.2978723404255319}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='8901' max='8901' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [8901/8901 15:06, Epoch 9/9]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.500400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.173800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.436500</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.493400</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.082500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.266300</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.903400</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.911200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.692600</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.766400</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.499700</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.698300</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.452600</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.524000</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.423000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.419800</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.394200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["9 9 9\n","[2022-03-30 08:13:40,776 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.2978723404255319, \"exact_match\": 0.0, \"f1\": 0.2978723404255319}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9890' max='9890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9890/9890 16:46, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.500800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.175600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.447000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.499600</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.061700</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.275800</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.919500</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.905400</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.736100</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.792900</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.515600</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.736700</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.476700</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.602600</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.465700</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.473000</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.416800</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.368300</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.318100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["10 10 10\n","[2022-03-30 08:30:40,873 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.25, \"exact_match\": 0.0, \"f1\": 0.25}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10879' max='10879' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10879/10879 18:24, Epoch 11/11]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.501300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.175700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.444100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.529000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.044800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.283800</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.916400</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.924400</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.727700</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.782500</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.532200</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.791200</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.483900</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.644900</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.528700</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.482800</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.460600</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.427000</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.355100</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.414100</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.394200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["11 11 11\n","[2022-03-30 08:49:18,714 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.2978723404255319, \"exact_match\": 0.0, \"f1\": 0.2978723404255319}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='11868' max='11868' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11868/11868 20:07, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.501600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.175200</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.443800</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.497000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.066800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.269400</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.939200</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.923000</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.770400</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.803700</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.541400</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.759200</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.457000</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.632300</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.528400</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.544600</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.480300</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.438600</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.375400</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.434400</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.404700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.356100</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.323000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["12 12 12\n","[2022-03-30 09:09:38,647 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.25, \"exact_match\": 0.0, \"f1\": 0.25}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='12857' max='12857' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [12857/12857 21:55, Epoch 13/13]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.501900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.178400</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.438000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.529400</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.092600</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.302000</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.957400</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.965000</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.731800</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.801900</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.563900</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.783500</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.466500</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.606400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.569700</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.556700</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.486800</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.442800</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.399400</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.472900</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.383100</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.421800</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.337300</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.332500</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.355600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["13 13 13\n","[2022-03-30 09:31:47,142 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.14285714285714285, \"exact_match\": 0.0, \"f1\": 0.14285714285714285}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='13846' max='13846' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13846/13846 23:32, Epoch 14/14]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.502300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.174700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.444300</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.504600</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.021600</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.294600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.977100</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.943700</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.767300</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.789600</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.589100</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.823600</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.507800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.685600</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.579900</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.533500</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.502100</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.476700</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.386700</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.482300</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.432800</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.402400</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.332700</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.407400</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.367200</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.393000</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.303400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["14 14 14\n","[2022-03-30 09:55:32,334 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 1 records from /content/drive/MyDrive/test_data2.jsonl\n","The run file is correct.\n","{\"pRR\": 0.30434782608695654, \"exact_match\": 0.0, \"f1\": 0.30434782608695654}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9737' max='14835' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 9737/14835 16:32 < 08:39, 9.81 it/s, Epoch 9.84/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.502300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.182900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.484800</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.500200</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.087800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.257900</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.959000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.944200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.752600</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.840500</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.614700</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.839500</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.489800</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.633600</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.618000</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.498100</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.582800</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.495400</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.456200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-f3b0d71ac6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_train_epochs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFine_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;31m#os.makedirs('wissam')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wissam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-c2c0a17a17b5>\u001b[0m in \u001b[0;36mFine_tune\u001b[0;34m(model_name, traindata, devdata, num_train_epochs, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m                    \u001b[0;31m#per_device_eval_batch_size=batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                    \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                    \u001b[0;31m#load_best_model_at_end=False, # change this to True after hyperparameter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                    )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/txtai/pipeline/train/hftrainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, base, train, validation, columns, maxlength, stride, task, **args)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Run training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# Run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m                 ):\n\u001b[1;32m   1407\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_train_epochs=2\n","model_name = \"wissamantoun/araelectra-base-artydiqa\" #num_train_epochs=2\n","batch_size=1\n","\n","print(\"\\n\\n###################\"+model_name)\n","tokenizer_wissam = AutoTokenizer.from_pretrained(model_name)\n","model_wissam = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","result = test_model(tokenizer_wissam,model_wissam,test_data3,5)\n","open('./quranqa/datasets/wissam_RunID.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/wissam_RunID.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","\n","for num_train_epochs in range(2,20):\n","  model, tokenizer = Fine_tune(model_name,dev_train_data,test_data3,num_train_epochs,batch_size)\n","  #os.makedirs('wissam')\n","  model.save_pretrained('wissam')\n","  tokenizer.save_pretrained('wissam')\n","  tokenizer1 = AutoTokenizer.from_pretrained('./wissam')\n","  model1 = AutoModelForQuestionAnswering.from_pretrained('./wissam')\n","  result = test_model(tokenizer1,model1,test_data3,5)\n","  open('./quranqa/datasets/wissam_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","  print(num_train_epochs,num_train_epochs,num_train_epochs)\n","  !python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/wissam_Run{num_train_epochs}F.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","\n"]},{"cell_type":"code","source":["model_name = \"salti/AraElectra-base-finetuned-ARCD\" #num_train_epochs=2\n","num_train_epochs=8\n","batch_size=1\n","\n","print(\"\\n\\n###################\"+model_name)\n","tokenizer_salti = AutoTokenizer.from_pretrained(model_name)\n","model_salti = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","result = test_model(tokenizer_salti,model_salti,test_data3,5)\n","open('./quranqa/datasets/salti_RunID.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_RunID.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","\n","model_salti2, tokenizer_salti2 = Fine_tune(model_name,dev_train_data,test_data3,num_train_epochs,batch_size)\n","os.makedirs('salti')\n","model_salti2.save_pretrained('salti')\n","tokenizer_salti2.save_pretrained('salti')\n","tokenizer_salti2 = AutoTokenizer.from_pretrained('./salti')\n","model_salti2 = AutoModelForQuestionAnswering.from_pretrained('./salti')\n","result = test_model(tokenizer_salti2,model_salti2,test_data3,5)\n","open('./quranqa/datasets/salti_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_Run{num_train_epochs}F.json' --gold_answers_file '/content/drive/MyDrive/test_data2.jsonl'\n","\n"],"metadata":{"id":"NTMd1GX-lM3p"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xriz8HUu324Y"},"outputs":[],"source":["model_name = \"salti/AraElectra-base-finetuned-ARCD\" #num_train_epochs=2\n","num_train_epochs=8\n","batch_size=1\n","\n","print(\"\\n\\n###################\"+model_name)\n","tokenizer_salti = AutoTokenizer.from_pretrained(model_name)\n","model_salti = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","result = test_model(tokenizer_salti,model_salti,dev_data,5)\n","open('./quranqa/datasets/salti_RunID.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_RunID.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","\n","model, tokenizer = Fine_tune(model_name,train_data,dev_data,num_train_epochs,batch_size)\n","os.makedirs('salti')\n","model.save_pretrained('salti')\n","tokenizer.save_pretrained('salti')\n","tokenizer = AutoTokenizer.from_pretrained('./salti')\n","model = AutoModelForQuestionAnswering.from_pretrained('./salti')\n","result = test_model(tokenizer,model,dev_data,5)\n","open('./quranqa/datasets/salti_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LdFFEL6osM0R"},"outputs":[],"source":["def post_ir(query, docs, index_method='lsi', dims=4):\n","    texts = [\n","        [word for word in doc.split()]\n","        for doc in docs\n","    ]\n","\n","    # build dictionary and corpus \n","    dictionary = corpora.Dictionary(texts)\n","    corpus = [dictionary.doc2bow(text) for text in texts]\n","\n","    # build tfidf & lsi models \n","    tfidf = models.TfidfModel(corpus) \n","    corpus_tfidf = tfidf[corpus]\n","    lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=dims)\n","    corpus_lsi = lsi_model[corpus_tfidf]\n","\n","    # generate query BOW vector and LSI vector from the question \n","    query_bow = query.replace('؟', '').replace('\"', '').split()\n","    vec_bow = dictionary.doc2bow(query_bow)\n","    vec_lsi = lsi_model[vec_bow]\n","\n","    result = []\n","    try:\n","        # generate tfidf and lsi indices \n","        lsi_index = similarities.MatrixSimilarity(corpus_lsi)\n","        tfidf_index = similarities.MatrixSimilarity(corpus_tfidf)\n","        \n","        \n","        # get similarities between queries and docs \n","        tfidf_sims = tfidf_index[vec_bow]\n","        lsi_sims = lsi_index[vec_lsi]\n","\n","        # sort documents according to similarties \n","        \n","        if index_method == 'tfidf':\n","            sims = tfidf_sims\n","        else:\n","            sims = lsi_sims\n","        \n","        sims = sorted(enumerate(sims), key=lambda item: -item[1])\n","        for doc_position, doc_score in sims:\n","            result.append( (doc_score, docs[doc_position]) )\n","    except:\n","        for doc in docs:\n","            result.append( (0.0, doc) )\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7KhvLPN6BLG"},"outputs":[],"source":["def rescoring(dev_data,result):\n","  results1 = {}\n","  results2 = {}\n","  results3 = {}\n","  results4 = {}\n","  scores = []\n","  for row in dev_data:\n","    for ans in result[row['pq_id']]:\n","      scores.append(ans['score'])\n","\n","  for row in dev_data:\n","    rank = 1\n","    l = []\n","    l2 = []\n","    \n","    for ans in result[row['pq_id']]:\n","      answer = ans['answer']\n","      score = ans['score']\n","      scores_norm = (score-min(scores))/(max(scores)-min(scores))\n","      if '؟' not in answer:\n","        ans = answer.split('.')\n","        for an in ans:\n","          if an!='' and '#' not in an:\n","            r = {'answer':an,'rank':rank,'score':scores_norm}\n","            if rank<6:\n","              l.append(r)\n","            l2.append(r)\n","            rank = rank +1\n","            scores_norm = scores_norm - 0.0001\n","            \n","    results1[row['pq_id']] = l \n","    results3[row['pq_id']] = l2\n","\n","    scores0 = {}\n","    scores1 = {}\n","    scores2 = {}\n","\n","    docs = []\n","    query = row['question']\n","    for ans in results3[row['pq_id']]:\n","      docs.append(ans['answer'])\n","      scores1[ans['answer']] = ans['score']\n","\n","    sim_scores = post_ir(query, docs)\n","    for sc, snt in sim_scores:\n","      scores2[snt] = sc\n","\n","    for k in scores1.keys():\n","      scores0[k] = scores1[k]+(scores2[k]+0.01)\n","\n","    scores0 = dict(sorted(scores0.items(), key=lambda item: item[1], reverse=True))\n","\n","\n","    l = []\n","    rank = 1\n","    for k in scores0.keys():\n","      r = {'answer':k,'rank':rank,'score':scores0[k]}\n","      if rank<6:\n","        l.append(r)\n","      l2.append(r)\n","      rank = rank +1\n","\n","    results2[row['pq_id']] = l \n","    results4[row['pq_id']] = l2\n","\n","  return results1,results2,results3,results4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUT3UD51djcX"},"outputs":[],"source":["num_train_epochs=0\n","\n","tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/wissamantoun')\n","model = AutoModelForQuestionAnswering.from_pretrained('/content/drive/MyDrive/wissamantoun')\n","\n","result = test_model(tokenizer,model,dev_data,5)\n","result2 = test_model2(tokenizer,model,dev_data)\n","open('./quranqa/datasets/wissam_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/wissam_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtcaXeecdl8R"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/wissamantoun')\n","model = AutoModelForQuestionAnswering.from_pretrained('/content/drive/MyDrive/wissamantoun')\n","\n","result = test_model(tokenizer,model,dev_data,20)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DCZHtITm6Ne_"},"outputs":[],"source":["results11,results12,results13,results14 = rescoring(dev_data,result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14050,"status":"ok","timestamp":1648412880783,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"Ct0vP0Rvra-r","outputId":"cc8fb555-c318-4120-faa2-673d144b8b1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2022-03-27 20:27:46,984 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.6442512889184745, \"exact_match\": 0.3669724770642202, \"f1\": 0.5952395968816058}\n","[2022-03-27 20:27:53,859 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.6124976858881551, \"exact_match\": 0.3486238532110092, \"f1\": 0.5560022602483338}\n"]}],"source":["num_train_epochs=1\n","open('./quranqa/datasets/wissam_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(results11,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/wissam_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","\n","num_train_epochs=2\n","open('./quranqa/datasets/wissam_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(results12,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/wissam_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42257,"status":"ok","timestamp":1648412941965,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"lybHOrlT2Cf3","outputId":"dd982e28-d960-4a9e-f953-ccbdcb671f19"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2022-03-27 20:28:54,743 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.6243208403005245, \"exact_match\": 0.3669724770642202, \"f1\": 0.5867165193384595}\n"]}],"source":["num_train_epochs=0\n","tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/salti')\n","model = AutoModelForQuestionAnswering.from_pretrained('/content/drive/MyDrive/salti')\n","\n","result = test_model(tokenizer,model,dev_data,5)\n","open('./quranqa/datasets/salti_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNAWDqGz1j_Z"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/salti')\n","model = AutoModelForQuestionAnswering.from_pretrained('/content/drive/MyDrive/salti')\n","\n","result = test_model(tokenizer,model,dev_data,20)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zNvRHvSf0h7"},"outputs":[],"source":["results21,results22,results23,results24 = rescoring(dev_data,result)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12617,"status":"ok","timestamp":1648412994900,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"46AjFcSOogmm","outputId":"ca2a33da-da99-452b-a8eb-252ab8136203"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2022-03-27 20:29:41,221 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.609003748199461, \"exact_match\": 0.3486238532110092, \"f1\": 0.5549594982285045}\n","[2022-03-27 20:29:47,893 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.5593736585071185, \"exact_match\": 0.3211009174311927, \"f1\": 0.5004948069154099}\n"]}],"source":["num_train_epochs=1\n","open('./quranqa/datasets/salti_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(results21,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","\n","num_train_epochs=2\n","open('./quranqa/datasets/salti_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(results22,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMIQ7m1mgCAX"},"outputs":[],"source":["with open('./quranqa/datasets/wissam_Run1F.json', 'r') as f:\n","  wissam_RunIDF = json.load(f)\n","\n","with open('./quranqa/datasets/salti_Run0F.json', 'r') as f:\n","  salti_RunIDF = json.load(f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7614,"status":"ok","timestamp":1648413009458,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"PsXTEPpZgBs4","outputId":"15ce5be5-bb11-4475-880d-cd647efc81d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2022-03-27 20:30:01,793 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.6176734894102516, \"exact_match\": 0.3761467889908257, \"f1\": 0.5741020757810674}\n"]}],"source":["\n","result = {}\n","for wissam_pq_dict,_ in zip(wissam_RunIDF,salti_RunIDF):\n","    ans_score = dict()\n","    for answer in wissam_RunIDF[wissam_pq_dict]:\n","        if answer[\"answer\"] not in ans_score.keys():\n","            ans_score[answer[\"answer\"]] = answer[\"score\"]*1\n","        elif answer[\"score\"] > ans_score[answer[\"answer\"]] :\n","            ans_score[answer[\"answer\"]] = answer[\"score\"]*1\n","        \n","    for answer in salti_RunIDF[wissam_pq_dict]:\n","        if answer[\"answer\"] not in ans_score.keys():\n","            ans_score[answer[\"answer\"]] = answer[\"score\"]*0.1\n","        elif answer[\"score\"] > ans_score[answer[\"answer\"]] :\n","            ans_score[answer[\"answer\"]] = answer[\"score\"]*0.1\n","     \n","    ans_score_sorted = dict(sorted(ans_score.items(), key=operator.itemgetter(1),reverse=True)) \n","    answers = []\n","    rank = 1\n","    for k in ans_score_sorted:\n","        answer = {}\n","        answer[\"answer\"] = k\n","        answer[\"rank\"] = rank\n","        answer[\"score\"] = ans_score_sorted[k]\n","        rank = rank +1\n","        answers.append(answer)\n","        if rank == 6:\n","            break\n","    result[wissam_pq_dict] = answers\n","    #break\n","    \n","open('./quranqa/datasets/w2s11_RunIDF.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/w2s11_RunIDF.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WQNuoLaTgBMd"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9069,"status":"ok","timestamp":1648160886368,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-120},"id":"ZQKsGqV17o1I","outputId":"49f91b24-8175-4f48-c002-f238d5c1e583"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at salti/AraElectra-base-finetuned-ARCD were not used when initializing ElectraModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["\n","# Create embeddings model, backed by sentence-transformers & transformers\n","embeddings = Embeddings({\"path\": model_name,\"context\":3})\n","\n","# Create extractor instance\n","extractor = Extractor(embeddings, model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8093,"status":"ok","timestamp":1648166253821,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-120},"id":"AaSZu2oX7oiI","outputId":"15593c49-dd7a-4d9b-9848-5eb7acae7360"},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"]},{"data":{"text/plain":["[(0, 0.6845324039459229), (1, 0.0025504184886813164)]"]},"execution_count":131,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Create and run pipeline\n","similarity = Similarity()\n","q = \"feel good story\"\n","d = [\"Maine man wins $1M from $25 lottery ticket\", \n","    \"Don't sacrifice slower friends in a bear attack\"]\n","similarity(q, d)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":720,"status":"error","timestamp":1648326515107,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"Mk4twUGrU_OV","outputId":"e7d76ac1-5fb0-4d21-84f9-171199532baf"},"outputs":[{"ename":"OSError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1928\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   2124\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2125\u001b[0;31m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2126\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RepoNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"404 Client Error: Repository Not Found for url: {request.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2047\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EntryNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error: Repository Not Found for url: https://huggingface.co/wissam/resolve/main/config.json","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-01973a6b6a1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create and run pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./wissam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/txtai/pipeline/text/labels.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, quantize, gpu, model, dynamic)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zero-shot-classification\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdynamic\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"text-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Set if labels are dynamic (zero shot) or fixed (standard text classification)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/txtai/pipeline/hfpipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task, path, quantize, gpu, model)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeviceid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeviceid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Model quantization. Compresses model to int8 precision, improves runtime performance. Only supported on CPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_from_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             raise EnvironmentError(\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;34mf\"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier listed on \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token having \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;34m\"permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: ./wissam is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."]}],"source":["\n","cont = 'وإذ ابتلى إبراهيم ربه بكلمات فأتمهن قال إني جاعلك للناس إماما قال ومن ذريتي قال لا ينال عهدي الظالمين. وإذ جعلنا البيت مثابة للناس وأمنا واتخذوا من مقام إبراهيم مصلى وعهدنا إلى إبراهيم وإسماعيل أن طهرا بيتي للطائفين والعاكفين والركع السجود. وإذ قال إبراهيم رب اجعل هذا بلدا آمنا وارزق أهله من الثمرات من آمن منهم بالله واليوم الآخر قال ومن كفر فأمتعه قليلا ثم أضطره إلى عذاب النار وبئس المصير. وإذ يرفع إبراهيم القواعد من البيت وإسماعيل ربنا تقبل منا إنك أنت السميع العليم. ربنا واجعلنا مسلمين لك ومن ذريتنا أمة مسلمة لك وأرنا مناسكنا وتب علينا إنك أنت التواب الرحيم. ربنا وابعث فيهم رسولا منهم يتلو عليهم آياتك ويعلمهم الكتاب والحكمة ويزكيهم إنك أنت العزيز الحكيم.'\n","q = 'من بنى الكعبة'\n","qu = ['من بنى الكعبة']\n","data = cont.split('.')\n","\n","# Create and run pipeline\n","similarity = Similarity('./wissam')\n","similarity(q, data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9403,"status":"ok","timestamp":1648164035514,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-120},"id":"aRDtUjleKu59","outputId":"380bcb89-2300-4f1d-c8d3-c162250edc81"},"outputs":[{"data":{"text/plain":["[('What team won the game?', 'Braves'), ('What was score?', '2-1')]"]},"execution_count":103,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Create embeddings model, backed by sentence-transformers & transformers\n","embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\"})\n","\n","# Create extractor instance\n","extractor = Extractor(embeddings, \"distilbert-base-cased-distilled-squad\")\n","data = [\"Giants hit 3 HRs to down Dodgers\",\n","        \"Giants 5 Dodgers 4 final\",\n","        \"Dodgers drop Game 2 against the Giants, 5-4\",\n","        \"Blue Jays beat Red Sox final score 2-1\",\n","        \"Red Sox lost to the Blue Jays, 2-1\",\n","        \"Blue Jays at Red Sox is over. Score: 2-1\",\n","        \"Phillies win over the Braves, 5-0\",\n","        \"Phillies 5 Braves 0 final\",\n","        \"Final: Braves lose to the Phillies in the series opener, 5-0\",\n","        \"Lightning goaltender pulled, lose to Flyers 4-1\",\n","        \"Flyers 4 Lightning 1 final\",\n","        \"Flyers win 4-1\"]\n","\n","questions = [\"What team won the game?\", \"What was score?\"]\n","\n","extractor([(question, question, question, False) for question in questions], data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1648198297229,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"8GKbmClxRbDn","outputId":"28ee57a1-b590-4725-899e-fce523de52d3"},"outputs":[{"data":{"text/plain":["{'answers': 'للفقراء والمساكين والعاملين عليها والمؤلفة قلوبهم وفي الرقاب والغارمين وفي سبيل الله وابن السبيل',\n"," 'context': 'إنما الصدقات للفقراء والمساكين والعاملين عليها والمؤلفة قلوبهم وفي الرقاب والغارمين وفي سبيل الله وابن السبيل فريضة من الله والله عليم حكيم. ومنهم الذين يؤذون النبي ويقولون هو أذن قل أذن خير لكم يؤمن بالله ويؤمن للمؤمنين ورحمة للذين آمنوا منكم والذين يؤذون رسول الله لهم عذاب أليم.',\n"," 'pq_id': '9:60-61_316',\n"," 'question': 'ما هي مصارف الزكاة؟'}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["dev_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14457,"status":"ok","timestamp":1648219743930,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"Rt7_9p1xRgHm","outputId":"837f408a-60b5-49d6-d6bc-5109b3236f25"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:999: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  UserWarning,\n"]},{"name":"stdout","output_type":"stream","text":["[2022-03-25 14:48:57,742 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","Unanswered question 9:122-123_400 will receive score 0.\n","Unanswered question 39:9-10_313 will receive score 0.\n","Unanswered question 33:56-59_348 will receive score 0.\n","Unanswered question 3:164-165_415 will receive score 0.\n","Unanswered question 48:16-17_415 will receive score 0.\n","Unanswered question 49:6-8_415 will receive score 0.\n","{\"pRR\": 0.32898166805660595, \"exact_match\": 0.1559633027522936, \"f1\": 0.28199300445676023}\n"]}],"source":["\n","result ={}\n","tokenizer = AutoTokenizer.from_pretrained('./wissam')\n","model = AutoModelForQuestionAnswering.from_pretrained('./wissam')\n","questions = Questions(path=(model, tokenizer), gpu=True)\n","i=0\n","for row in dev_data:\n","  data = row['context'].split('.')\n","  qu = [row['question']]\n","  rank = 1\n","  \n","  answers = []\n","\n","  ans = list(set(questions([qu[0]] * len(data), data)))\n","  for r in ans:\n","    if r != None:\n","      answer = {}\n","      answer[\"answer\"] = r\n","      answer[\"rank\"] = rank\n","      answer[\"score\"] = 5 - rank\n","      rank = rank +1\n","      answers.append(answer)\n","    if rank == 6:\n","        break\n","        \n","  if len(answers):\n","    result[row[\"pq_id\"]] = answers\n","  i = i+1\n","  '''if i==18:\n","    print(answers)\n","    break'''\n","\n","\n","open('./quranqa/datasets/Que_Run1F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/Que_Run1F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1648203777458,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"EOrQa-MPTTOF","outputId":"367e9244-5ab1-4a33-cecc-08b1187123f4"},"outputs":[{"data":{"text/plain":["[{'answer': 'ولكم في القصاص حياة', 'rank': 1, 'score': 4},\n"," {'answer': 'كتب عليكم القصاص في القتلى الحر بالحر والعبد بالعبد والأنثى بالأنثى',\n","  'rank': 2,\n","  'score': 3}]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["\n","result['2:178-179_400']\n","\n"]},{"cell_type":"code","source":["!python ./quranqa/code/quranqa22_eval.py --run_file '/content/drive/MyDrive/results/paper/QQATeam_Run1.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"frK5g0ohQNWB","executionInfo":{"status":"ok","timestamp":1649137548087,"user_tz":-180,"elapsed":22028,"user":{"displayName":"Qa Task","userId":"02359377570863894136"}},"outputId":"c6a44261-e848-468b-82b3-8674bf7cf2df"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/urllib3/connectionpool.py:988: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n","  InsecureRequestWarning,\n","100% 241M/241M [00:13<00:00, 18.0MiB/s]\n","[2022-04-05 05:45:42,382 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","{\"pRR\": 0.6313448903022509, \"exact_match\": 0.3669724770642202, \"f1\": 0.6030726642357181}\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"quran-qa-wissam.ipynb","provenance":[{"file_id":"13nPzPvxah0kwFlE6rEV_yrQ0xIaBjnLs","timestamp":1648240825868}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}