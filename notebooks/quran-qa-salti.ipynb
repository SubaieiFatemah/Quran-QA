{"cells":[{"cell_type":"code","execution_count":124,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1648240473286,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"iQItrfLQYCx2","outputId":"f7b2884f-56e5-47fe-8360-7047cc5b51da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Mar 25 20:34:33 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16894,"status":"ok","timestamp":1648240492029,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"ZkoOGYWeXjhl","outputId":"9610ade8-659d-455e-fb5f-59467caddf46"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'quranqa' already exists and is not an empty directory.\n","Collecting git+https://github.com/neuml/txtai\n","  Cloning https://github.com/neuml/txtai to /tmp/pip-req-build-tsjqnk85\n","  Running command git clone -q https://github.com/neuml/txtai /tmp/pip-req-build-tsjqnk85\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: faiss-cpu>=1.7.1.post2 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (1.7.2)\n","Requirement already satisfied: transformers>=4.12.3 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (4.17.0)\n","Requirement already satisfied: numpy>=1.18.4 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (1.21.5)\n","Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (6.0)\n","Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (0.11.6)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from txtai==4.4.0) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->txtai==4.4.0) (3.10.0.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (0.0.49)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (4.63.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (3.6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (0.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.12.3->txtai==4.4.0) (2019.12.20)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.12.3->txtai==4.4.0) (3.0.7)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.12.3->txtai==4.4.0) (1.25.11)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.12.3->txtai==4.4.0) (3.7.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.12.3->txtai==4.4.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.12.3->txtai==4.4.0) (1.1.0)\n","Requirement already satisfied: farasapy in /usr/local/lib/python3.7/dist-packages (0.0.14)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farasapy) (4.63.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farasapy) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farasapy) (3.0.4)\n"]}],"source":["!git clone https://gitlab.com/bigirqu/quranqa.git\n","!pip install git+https://github.com/neuml/txtai datasets pandas\n","!pip install farasapy"]},{"cell_type":"code","execution_count":126,"metadata":{"id":"cNT1MBHKXjhs","executionInfo":{"status":"ok","timestamp":1648240492030,"user_tz":-180,"elapsed":66,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"outputs":[],"source":["import sys\n","sys.path.insert(1, '/content/quranqa/code')\n","\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","from txtai.pipeline import HFTrainer\n","import torch, string, re, os, json\n","import operator\n","\n","from farasa.pos import FarasaPOSTagger \n","from farasa.ner import FarasaNamedEntityRecognizer \n","from farasa.diacratizer import FarasaDiacritizer \n","from farasa.segmenter import FarasaSegmenter \n","from farasa.stemmer import FarasaStemmer\n","\n","import read_write_qrcd as q_reader\n","from gensim import corpora, models, similarities\n","from collections import defaultdict\n","import pprint"]},{"cell_type":"code","execution_count":127,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65,"status":"ok","timestamp":1648240492030,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"I12lpmBwXjht","outputId":"a6a7e4ed-3bdc-4d87-a4fd-25b350f4281f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 710 records from ./quranqa/datasets/qrcd_v1.1_train.jsonl\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n"]}],"source":["train_passage_question_objects = q_reader.load_jsonl('./quranqa/datasets/qrcd_v1.1_train.jsonl')\n","dev_passage_question_objects = q_reader.load_jsonl('./quranqa/datasets/qrcd_v1.1_dev.jsonl')\n"]},{"cell_type":"code","execution_count":128,"metadata":{"id":"jddATQh7Xjhu","executionInfo":{"status":"ok","timestamp":1648240492031,"user_tz":-180,"elapsed":64,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"outputs":[],"source":["\n","train_data = [dict({\"pq_id\": passage_question_object['pq_id'],\n","                    #\"question\": quranqa22_eval.normalize_text(passage_question_object.question),\n","                    \"question\": passage_question_object['question'],\n","                    \"passage\": passage_question_object['passage'], \n","                    \"answers\": r['text']})\n","              for passage_question_object in train_passage_question_objects\n","              for r in passage_question_object['answers']]\n","\n","\n","dev_data = [dict({\"pq_id\": passage_question_object['pq_id'],\n","                  #\"question\": quranqa22_eval.normalize_text(passage_question_object.question),\n","                  \"question\": passage_question_object['question'],\n","                  \"passage\": passage_question_object['passage'],\n","                  \"answers\": r['text']})\n","            for passage_question_object in dev_passage_question_objects\n","            for r in passage_question_object['answers']]\n","\n"]},{"cell_type":"code","execution_count":129,"metadata":{"executionInfo":{"elapsed":63,"status":"ok","timestamp":1648240492031,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"HUbGcz9k5qwa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"33c9bd98-3665-4601-9a98-afdc7caaa354"},"outputs":[{"output_type":"stream","name":"stdout","text":["cp: target '/content/drive/MyDrive' is not a directory\n"]}],"source":["import pandas as pd\n","dev_data_df = pd.DataFrame(dev_data)\n","dev_data_df.to_csv('dev.csv', sep='\\t')\n","train_data_df = pd.DataFrame(train_data)\n","train_data_df.to_csv('train.csv', sep='\\t')\n","\n","!cp *.csv /content/drive/MyDrive"]},{"cell_type":"code","execution_count":130,"metadata":{"id":"yKCvBkzHXjhv","executionInfo":{"status":"ok","timestamp":1648240492031,"user_tz":-180,"elapsed":59,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"outputs":[],"source":["pretrained_models = [#\"wissamantoun/araelectra-base-artydiqa\", #num_train_epochs=2\n","                     #\"salti/AraElectra-base-finetuned-ARCD\", #num_train_epochs=8\n","                     \"gfdgdfgdg/arap_qa_bert_large_v2\",\n","                     #\"gfdgdfgdg/arap_qa_bert_v2\",\n","                     #\"gfdgdfgdg/arap_qa_bert\"\n","                     ]\n","\n","\n","def tokenize_function(row,tokenizer):\n","    return tokenizer.encode_plus(row['question'], row['passage'], \n","                                 return_tensors='pt', padding=True, \n","                                 truncation=True,max_length=512, \n","                                 add_special_tokens = True)\n","\n","topk_n = 20\n","def get_prediction(row, model, tokenizer):\n","    inputs = tokenize_function(row,tokenizer)\n","    output = model(**inputs)\n","    \n","    #print(torch.topk(output.start_logits.flatten(), topk_n))\n","    answer_starts_val = torch.topk(output.start_logits.flatten(), topk_n).values\n","    answer_ends_val = torch.topk(output.end_logits.flatten(), topk_n).values\n","    answer_starts = torch.topk(output.start_logits.flatten(), topk_n).indices\n","    answer_ends = torch.topk(output.end_logits.flatten(), topk_n).indices\n","    \n","    answers = []\n","    rank = 1\n","    for answer_start,answer_end,answer_start_v,answer_end_v in zip(answer_starts,answer_ends,answer_starts_val,answer_ends_val):\n","        answer = {}\n","        ans = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end+1]))\n","        if len(ans.strip())>0:\n","            answer[\"answer\"] = ans\n","            answer[\"rank\"] = rank\n","            answer[\"score\"] = answer_start_v.item()+answer_end_v.item()\n","            rank = rank +1\n","            answers.append(answer)\n","        if rank == 6:\n","            break\n","        #answer = str(answer_start_v.item())+' '+ answer +' '+ str(answer_end_v.item())\n","    return answers\n"]},{"cell_type":"code","source":["\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","def compute_f1(prediction, truth):\n","    print(tokenizer.decode(prediction[0]))\n","    print(tokenizer.decode(prediction))\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","    \n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","    \n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","    \n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","    \n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","    \n","    return 2 * (prec * rec) / (prec + rec)\n","\n","def compute_metrics(p):\n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    exact_match = compute_exact_match(pred, labels)\n","    f1 = compute_f1(pred, labels)\n","\n","    return { \"f1\": f1, \"exact_match\": exact_match}\n"],"metadata":{"id":"y78egEpg1vSI","executionInfo":{"status":"ok","timestamp":1648240492032,"user_tz":-180,"elapsed":59,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"execution_count":131,"outputs":[]},{"cell_type":"code","execution_count":132,"metadata":{"id":"r8dprFZjXjhw","executionInfo":{"status":"ok","timestamp":1648240492032,"user_tz":-180,"elapsed":58,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"outputs":[],"source":["from transformers import EarlyStoppingCallback\n","\n","def Fine_tune(model_name,traindata,devdata,num_train_epochs,batch_size):\n","    trainer = HFTrainer()\n","\n","    return trainer(model_name, traindata,#devdata,\n","                   task=\"question-answering\",\n","                   metric_for_best_model = 'f1',\n","                   #evaluation_strategy ='epoch',\n","                   #eval_steps = 500, # Evaluation and Save happens every 50 steps\n","                   #save_total_limit = 15,\n","                   save_strategy='no',\n","                   learning_rate=2e-5,\n","                   per_device_train_batch_size=batch_size,\n","                   #per_device_eval_batch_size=batch_size,\n","                   num_train_epochs=num_train_epochs,\n","                   weight_decay=0.01,\n","                   #load_best_model_at_end=False, # change this to True after hyperparameter tuning\n","                   )\n","    #return trainer(model_name, data, task=\"question-answering\", num_train_epochs=num_train_epochs)#num_train_epochs=10"]},{"cell_type":"code","source":["from gensim import corpora, models, similarities\n","from collections import defaultdict\n","import pprint\n","def ir(data_item={}, query_key='question', docs_key='passage', index_method='lsi', dims=4) -> list:\n","    # get data items \n","    docs = [ver.strip() for ver in data_item.get(docs_key).split('.') if ver.strip()]\n","    query = data_item.get(query_key)\n","    stoplist = ''.split()\n","    texts = [\n","        [word for word in doc.split() if word not in stoplist]\n","        for doc in docs\n","    ]\n","\n","    # build dictionary and corpus \n","    dictionary = corpora.Dictionary(texts)\n","    corpus = [dictionary.doc2bow(text) for text in texts]\n","\n","    # build tfidf & lsi models \n","    tfidf = models.TfidfModel(corpus) \n","    corpus_tfidf = tfidf[corpus]\n","    lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=dims)\n","    corpus_lsi = lsi_model[corpus_tfidf]\n","\n","    # generate query BOW vector and LSI vector from the question \n","    query_bow = query.replace('؟', '').replace('\"', '').split()\n","    vec_bow = dictionary.doc2bow(query_bow)\n","    vec_lsi = lsi_model[vec_bow]\n","\n","    result = []\n","    try:\n","        # generate tfidf and lsi indices \n","        lsi_index = similarities.MatrixSimilarity(corpus_lsi)\n","        tfidf_index = similarities.MatrixSimilarity(corpus_tfidf)\n","        \n","        \n","        # get similarities between queries and docs \n","        tfidf_sims = tfidf_index[vec_bow]\n","        lsi_sims = lsi_index[vec_lsi]\n","\n","        # sort documents according to similarties \n","        \n","        if index_method == 'tfidf':\n","            sims = tfidf_sims\n","        else:\n","            sims = lsi_sims\n","        \n","        sims = sorted(enumerate(sims), key=lambda item: -item[1])\n","        for doc_position, doc_score in sims:\n","            result.append( (doc_score, docs[doc_position]) )\n","    except:\n","        for doc in docs:\n","            result.append( (0.0, doc) )\n","    return result"],"metadata":{"id":"DobWLdpkjnh5","executionInfo":{"status":"ok","timestamp":1648240648755,"user_tz":-180,"elapsed":670,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["def filter_passage(in_data):\n","  f_train_data = []\n","  for data in in_data:\n","    filtered = ir(data_item=data)\n","    sc,worest = filtered[-1]\n","    passage = data['passage']\n","    if sc != 0:\n","      passage = passage.replace(worest,'')\n","    passage = passage.replace('  ',' ')\n","    passage = passage.replace(' .','.')\n","    passage = passage.replace('..','.')\n","    data['passage'] = passage\n","    f_train_data.append(data)\n","  return f_train_data"],"metadata":{"id":"RVQO4QEoohvM","executionInfo":{"status":"ok","timestamp":1648240649521,"user_tz":-180,"elapsed":2,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["f_train_data = filter_passage(train_data)\n","f_dev_data = filter_passage(dev_data)\n"],"metadata":{"id":"7mxDPxrckujk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":143,"metadata":{"id":"9YTn4NqeXjhx","executionInfo":{"status":"ok","timestamp":1648240699608,"user_tz":-180,"elapsed":701,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}}},"outputs":[],"source":["def test_model(tokenizer,model,data):\n","    result = {}\n","    for row in data:\n","        pred = get_prediction(row, model, tokenizer)\n","        result[row[\"pq_id\"]] = pred\n","    return result"]},{"cell_type":"code","execution_count":144,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":1387,"status":"error","timestamp":1648240839656,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"},"user_tz":-180},"id":"CJYAT9WeXjhy","outputId":"48cdda69-d202-4a2a-fb31-6a157d895856"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-144-92c6ae188491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n###################\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer_wissam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_wissam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"tuple\") to str"]}],"source":["model_name = \"salti/AraElectra-base-finetuned-ARCD\" #num_train_epochs=11\n","num_train_epochs=11\n","batch_size=1\n","\n","print(\"\\n\\n###################\"+model_name)\n","tokenizer_salti = AutoTokenizer.from_pretrained(model_name)\n","model_salti = AutoModelForQuestionAnswering.from_pretrained(model_name)\n","result = test_model(tokenizer_salti,model_salti,dev_data)\n","open('./quranqa/datasets/salti_RunID.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_RunID.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","\n","model, tokenizer = Fine_tune(model_name,train_data,dev_data,num_train_epochs,batch_size)\n","os.makedirs('salti')\n","model.save_pretrained('salti')\n","tokenizer.save_pretrained('salti')\n","tokenizer = AutoTokenizer.from_pretrained('./salti')\n","model = AutoModelForQuestionAnswering.from_pretrained('./salti')\n","result = test_model(tokenizer,model,dev_data)\n","open('./quranqa/datasets/salti_Run'+str(num_train_epochs)+'F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/salti_Run{num_train_epochs}F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n","\n"]},{"cell_type":"code","source":["from txtai.embeddings import Embeddings\n","from txtai.pipeline import Extractor\n","\n","# Create embeddings model, backed by sentence-transformers & transformers\n","embeddings = Embeddings({\"path\": model_name,\"passage\":3})\n","\n","# Create extractor instance\n","extractor = Extractor(embeddings, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQKsGqV17o1I","executionInfo":{"status":"ok","timestamp":1648160886368,"user_tz":-120,"elapsed":9069,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}},"outputId":"49f91b24-8175-4f48-c002-f238d5c1e583"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at salti/AraElectra-base-finetuned-ARCD were not used when initializing ElectraModel: ['qa_outputs.weight', 'qa_outputs.bias']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["from txtai.pipeline import Similarity\n","\n","# Create and run pipeline\n","similarity = Similarity()\n","q = \"feel good story\"\n","d = [\"Maine man wins $1M from $25 lottery ticket\", \n","    \"Don't sacrifice slower friends in a bear attack\"]\n","similarity(q, d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AaSZu2oX7oiI","executionInfo":{"status":"ok","timestamp":1648166253821,"user_tz":-120,"elapsed":8093,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}},"outputId":"15593c49-dd7a-4d9b-9848-5eb7acae7360"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"]},{"output_type":"execute_result","data":{"text/plain":["[(0, 0.6845324039459229), (1, 0.0025504184886813164)]"]},"metadata":{},"execution_count":131}]},{"cell_type":"code","source":["from txtai.pipeline import Similarity\n","cont = 'وإذ ابتلى إبراهيم ربه بكلمات فأتمهن قال إني جاعلك للناس إماما قال ومن ذريتي قال لا ينال عهدي الظالمين. وإذ جعلنا البيت مثابة للناس وأمنا واتخذوا من مقام إبراهيم مصلى وعهدنا إلى إبراهيم وإسماعيل أن طهرا بيتي للطائفين والعاكفين والركع السجود. وإذ قال إبراهيم رب اجعل هذا بلدا آمنا وارزق أهله من الثمرات من آمن منهم بالله واليوم الآخر قال ومن كفر فأمتعه قليلا ثم أضطره إلى عذاب النار وبئس المصير. وإذ يرفع إبراهيم القواعد من البيت وإسماعيل ربنا تقبل منا إنك أنت السميع العليم. ربنا واجعلنا مسلمين لك ومن ذريتنا أمة مسلمة لك وأرنا مناسكنا وتب علينا إنك أنت التواب الرحيم. ربنا وابعث فيهم رسولا منهم يتلو عليهم آياتك ويعلمهم الكتاب والحكمة ويزكيهم إنك أنت العزيز الحكيم.'\n","q = 'من بنى الكعبة'\n","qu = ['من بنى الكعبة']\n","data = cont.split('.')\n","\n","# Create and run pipeline\n","similarity = Similarity('./salti')\n","similarity(q, data)"],"metadata":{"id":"Mk4twUGrU_OV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from txtai.embeddings import Embeddings\n","from txtai.pipeline import Extractor\n","\n","# Create embeddings model, backed by sentence-transformers & transformers\n","embeddings = Embeddings({\"path\": \"sentence-transformers/nli-mpnet-base-v2\"})\n","\n","# Create extractor instance\n","extractor = Extractor(embeddings, \"distilbert-base-cased-distilled-squad\")\n","data = [\"Giants hit 3 HRs to down Dodgers\",\n","        \"Giants 5 Dodgers 4 final\",\n","        \"Dodgers drop Game 2 against the Giants, 5-4\",\n","        \"Blue Jays beat Red Sox final score 2-1\",\n","        \"Red Sox lost to the Blue Jays, 2-1\",\n","        \"Blue Jays at Red Sox is over. Score: 2-1\",\n","        \"Phillies win over the Braves, 5-0\",\n","        \"Phillies 5 Braves 0 final\",\n","        \"Final: Braves lose to the Phillies in the series opener, 5-0\",\n","        \"Lightning goaltender pulled, lose to Flyers 4-1\",\n","        \"Flyers 4 Lightning 1 final\",\n","        \"Flyers win 4-1\"]\n","\n","questions = [\"What team won the game?\", \"What was score?\"]\n","\n","extractor([(question, question, question, False) for question in questions], data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aRDtUjleKu59","executionInfo":{"status":"ok","timestamp":1648164035514,"user_tz":-120,"elapsed":9403,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}},"outputId":"380bcb89-2300-4f1d-c8d3-c162250edc81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('What team won the game?', 'Braves'), ('What was score?', '2-1')]"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["dev_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GKbmClxRbDn","executionInfo":{"status":"ok","timestamp":1648198297229,"user_tz":-180,"elapsed":4,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}},"outputId":"28ee57a1-b590-4725-899e-fce523de52d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'answers': 'للفقراء والمساكين والعاملين عليها والمؤلفة قلوبهم وفي الرقاب والغارمين وفي سبيل الله وابن السبيل',\n"," 'context': 'إنما الصدقات للفقراء والمساكين والعاملين عليها والمؤلفة قلوبهم وفي الرقاب والغارمين وفي سبيل الله وابن السبيل فريضة من الله والله عليم حكيم. ومنهم الذين يؤذون النبي ويقولون هو أذن قل أذن خير لكم يؤمن بالله ويؤمن للمؤمنين ورحمة للذين آمنوا منكم والذين يؤذون رسول الله لهم عذاب أليم.',\n"," 'pq_id': '9:60-61_316',\n"," 'question': 'ما هي مصارف الزكاة؟'}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from txtai.pipeline import Questions\n","result ={}\n","tokenizer = AutoTokenizer.from_pretrained('./salti')\n","model = AutoModelForQuestionAnswering.from_pretrained('./salti')\n","questions = Questions(path=(model, tokenizer), gpu=True)\n","i=0\n","for row in dev_data:\n","  data = row['passage'].split('.')\n","  qu = [row['question']]\n","  rank = 1\n","  \n","  answers = []\n","\n","  ans = list(set(questions([qu[0]] * len(data), data)))\n","  for r in ans:\n","    if r != None:\n","      answer = {}\n","      answer[\"answer\"] = r\n","      answer[\"rank\"] = rank\n","      answer[\"score\"] = 5 - rank\n","      rank = rank +1\n","      answers.append(answer)\n","    if rank == 6:\n","        break\n","        \n","  if len(answers):\n","    result[row[\"pq_id\"]] = answers\n","  i = i+1\n","  '''if i==18:\n","    print(answers)\n","    break'''\n","\n","\n","open('./quranqa/datasets/Que_Run1F.json' , \"w\", encoding=\"utf8\").write(json.dumps(result,indent=4, ensure_ascii=False))\n","!python ./quranqa/code/quranqa22_eval.py --run_file './quranqa/datasets/Que_Run1F.json' --gold_answers_file './quranqa/datasets/qrcd_v1.1_dev.jsonl'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rt7_9p1xRgHm","executionInfo":{"status":"ok","timestamp":1648219743930,"user_tz":-180,"elapsed":14457,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}},"outputId":"837f408a-60b5-49d6-d6bc-5109b3236f25"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py:999: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","  UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["[2022-03-25 14:48:57,742 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","Loaded 109 records from ./quranqa/datasets/qrcd_v1.1_dev.jsonl\n","The run file is correct.\n","Unanswered question 9:122-123_400 will receive score 0.\n","Unanswered question 39:9-10_313 will receive score 0.\n","Unanswered question 33:56-59_348 will receive score 0.\n","Unanswered question 3:164-165_415 will receive score 0.\n","Unanswered question 48:16-17_415 will receive score 0.\n","Unanswered question 49:6-8_415 will receive score 0.\n","{\"pRR\": 0.32898166805660595, \"exact_match\": 0.1559633027522936, \"f1\": 0.28199300445676023}\n"]}]},{"cell_type":"code","source":["\n","result['2:178-179_400']\n","\n"],"metadata":{"id":"EOrQa-MPTTOF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648203777458,"user_tz":-180,"elapsed":399,"user":{"displayName":"Qa Task","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02359377570863894136"}},"outputId":"367e9244-5ab1-4a33-cecc-08b1187123f4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'answer': 'ولكم في القصاص حياة', 'rank': 1, 'score': 4},\n"," {'answer': 'كتب عليكم القصاص في القتلى الحر بالحر والعبد بالعبد والأنثى بالأنثى',\n","  'rank': 2,\n","  'score': 3}]"]},"metadata":{},"execution_count":18}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"quran-qa-salti.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}